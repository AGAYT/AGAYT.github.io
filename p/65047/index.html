<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;agayt.github.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Mist&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.json&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script>
<meta name="description" content="hadoop单机版">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop安装教程">
<meta property="og:url" content="http://agayt.github.com/p/65047/index.html">
<meta property="og:site_name" content="阿甘的blog">
<meta property="og:description" content="hadoop单机版">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://testmybuck.oss-cn-beijing.aliyuncs.com/img/image-20220930183346132.png">
<meta property="og:image" content="https://testmybuck.oss-cn-beijing.aliyuncs.com/img/image-20220930184805278.png">
<meta property="article:published_time" content="2022-12-21T03:10:26.000Z">
<meta property="article:modified_time" content="2022-10-04T06:33:05.243Z">
<meta property="article:author" content="AGA">
<meta property="article:tag" content="hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://testmybuck.oss-cn-beijing.aliyuncs.com/img/image-20220930183346132.png">


<link rel="canonical" href="http://agayt.github.com/p/65047/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;agayt.github.com&#x2F;p&#x2F;65047&#x2F;&quot;,&quot;path&quot;:&quot;p&#x2F;65047&#x2F;&quot;,&quot;title&quot;:&quot;Hadoop安装教程&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>Hadoop安装教程 | 阿甘的blog</title><script src="/js/config.js"></script>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
 
<script type="text/javascript" src="/js/nest.js"></script>


  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">阿甘的blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">走过路过不要错过</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%89%E8%A3%85%E6%B5%81%E7%A8%8B"><span class="nav-number">1.</span> <span class="nav-text">安装流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7"><span class="nav-number">1.1.</span> <span class="nav-text">创建用户</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AEjava%E7%8E%AF%E5%A2%83"><span class="nav-number">1.2.</span> <span class="nav-text">配置java环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BDhadoop"><span class="nav-number">1.3.</span> <span class="nav-text">下载hadoop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">1.4.</span> <span class="nav-text">修改配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-number">1.5.</span> <span class="nav-text">初始化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%AF%E5%8A%A8"><span class="nav-number">1.6.</span> <span class="nav-text">启动</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95"><span class="nav-number">2.</span> <span class="nav-text">性能测试</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DFSIO"><span class="nav-number">2.1.</span> <span class="nav-text">DFSIO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nnbench"><span class="nav-number">2.2.</span> <span class="nav-text">nnbench</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mrbench"><span class="nav-number">2.3.</span> <span class="nav-text">mrbench</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C"><span class="nav-number">3.</span> <span class="nav-text">运行</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop%E7%9A%84fs%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="nav-number">3.1.</span> <span class="nav-text">hadoop的fs常用命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E7%A8%8B%E5%BA%8F%E8%AE%A1%E7%AE%97%E5%8D%95%E8%AF%8D%E6%80%BB%E6%95%B0"><span class="nav-number">3.2.</span> <span class="nav-text">MapReduce程序计算单词总数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86"><span class="nav-number">3.3.</span> <span class="nav-text">MapReduce程序运行原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB"><span class="nav-number">3.4.</span> <span class="nav-text">自定义类</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">AGA</p>
  <div class="site-description" itemprop="description">hiahiahia</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://agayt.github.com/p/65047/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="AGA">
      <meta itemprop="description" content="hiahiahia">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="阿甘的blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop安装教程
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-12-21 11:10:26" itemprop="dateCreated datePublished" datetime="2022-12-21T11:10:26+08:00">2022-12-21</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2022-10-04 14:33:05" itemprop="dateModified" datetime="2022-10-04T14:33:05+08:00">2022-10-04</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">hadoop单机版</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h2><p>Hadoop=HDFS(文件系统)+Mapreduce(计算程序)+YARN(资源分配)</p>
<h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><p>创建用户hadoop用于管理hadoop</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建hadoop用户</span></span><br><span class="line">sudo useradd -m hadoop -s /bin/bash</span><br><span class="line"><span class="comment"># 为用户设置密码</span></span><br><span class="line">sudo passwd hadoop</span><br></pre></td></tr></table></figure>

<p>修改/etc/sudoers文件，找到下面一行，把前面的注释（#）去掉</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Allows people in group wheel to run all commands</span></span><br><span class="line">%wheel ALL=(ALL) ALL</span><br><span class="line"><span class="comment"># 或者添加一行</span></span><br><span class="line">admin root ALL=(ALL) ALL</span><br></pre></td></tr></table></figure>



<h3 id="配置java环境"><a href="#配置java环境" class="headerlink" title="配置java环境"></a>配置java环境</h3><ol>
<li><p>下载<code>https://download.oracle.com/java/18/latest/jdk-18_linux-aarch64_bin.tar.gz</code>压缩包或者通过yum下载</p>
</li>
<li><p>解压<code>tar -zxvf jdk-18_linux-aarch64_bin.tar.gz</code> </p>
</li>
<li><p>配置环境变量</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_152            </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>



<h3 id="下载hadoop"><a href="#下载hadoop" class="headerlink" title="下载hadoop"></a>下载hadoop</h3><blockquote>
<p>先下载wget,<code>yum -y install wget</code></p>
<p>然后通过wget下载<code>wget https://downloads.apache.org/hadoop/common/hadoop-2.10.1/hadoop-2.10.1.tar.gz</code></p>
</blockquote>
<p>配置环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$sudo</span> vim ~/.bashrc  //打开环境变量目录写入</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">&quot;-Djava.library.path=<span class="variable">$HADOOP_HOME</span>/lib/native&quot;</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$&#123;HADOOP_HOME&#125;</span>/bin:<span class="variable">$&#123;HADOOP_HOME&#125;</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

<p>测试是否成功</p>
<p><code>hadoop -version</code></p>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>1.core-site.xml</p>
<p><strong>core-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abasefor other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>





<p>2.hdfs.site.xml,yarn-site.xml,mapreduce-site.xml</p>
<p><strong>hdfs.site</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>yarn-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>maped-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure>

<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动hdfs</span></span><br><span class="line">start-dfs.sh</span><br><span class="line"><span class="comment"># 停止hdfs</span></span><br><span class="line">stop-fds.sh</span><br><span class="line"><span class="comment"># 启动yarn</span></span><br><span class="line">start-yarn.sh</span><br><span class="line"><span class="comment"># 停止hdfs</span></span><br><span class="line">stop-yarn.sh</span><br><span class="line"><span class="comment"># 一起启动</span></span><br><span class="line">start-all.sh</span><br><span class="line"><span class="comment"># 一起停止</span></span><br><span class="line">stop-all.sh</span><br></pre></td></tr></table></figure>



<p>最后通过JPS查看java进程是否有NameNode(HDFS老大)，SecondaryNameNode(HDFS秘书)，DataNode(小弟)，ResourceManager(yarn老大),NodeManager(yarn小弟)</p>
<p>默认管理界面</p>
<blockquote>
<p>​    HDFS=&gt;192.168.1.200:9870</p>
<p>​    Yarn =&gt; 192.168.1.200:8088</p>
</blockquote>
<h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><h3 id="DFSIO"><a href="#DFSIO" class="headerlink" title="DFSIO"></a>DFSIO</h3><p><strong>写性能</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 128MB</span><br></pre></td></tr></table></figure>

<p><strong>读性能</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar TestDFSIO -<span class="built_in">read</span> -nrFiles 10 -fileSize 128MB</span><br></pre></td></tr></table></figure>

<p><strong>删除产生的文件</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar TestDFSIO -clean</span><br></pre></td></tr></table></figure>

<p>结果保存``TestDFSIO_results.log`</p>
<h3 id="nnbench"><a href="#nnbench" class="headerlink" title="nnbench"></a>nnbench</h3><p>测试NameNode的负载，它会生成很多与HDFS相关的请求，给NameNode施加较大的压力。这个测试能在HDFS上模拟创建、读取、重命名和删除文件等操作。nnbench的用法如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar nnbench -operation create_write -maps 4 -reduces 2 -blockSize 1 </span><br></pre></td></tr></table></figure>

<p>结果显示在最后</p>
<h3 id="mrbench"><a href="#mrbench" class="headerlink" title="mrbench"></a>mrbench</h3><p>mrbench会多次重复执行一个小作业，用于检查在机群上小作业的运行是否可重复以及运行是否高效</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar <span class="variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar mrbench -numRuns 50</span><br></pre></td></tr></table></figure>

<p>结果显示在最后</p>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><h3 id="hadoop的fs常用命令"><a href="#hadoop的fs常用命令" class="headerlink" title="hadoop的fs常用命令"></a><strong>hadoop的fs常用命令</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">Usage: hadoop fs [generic options]</span><br><span class="line">	[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-checksum &lt;src&gt; ...]</span><br><span class="line">	[-chgrp [-R] GROUP PATH...]</span><br><span class="line">	[-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">	[-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">	[-copyFromLocal [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-copyToLocal [-f] [-p] [-crc] [-ignoreCrc] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-count [-q] [-h] [-v] [-t [&lt;storage <span class="built_in">type</span>&gt;]] [-u] [-x] [-e] &lt;path&gt; ...]</span><br><span class="line">	[-cp [-f] [-p | -p[topax]] [-d] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span><br><span class="line">	[-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span><br><span class="line">	[-df [-h] [&lt;path&gt; ...]]</span><br><span class="line">	[-du [-s] [-h] [-v] [-x] &lt;path&gt; ...]</span><br><span class="line">	[-expunge [-immediate]]</span><br><span class="line">	[-find &lt;path&gt; ... &lt;expression&gt; ...]</span><br><span class="line">	[-get [-f] [-p] [-crc] [-ignoreCrc] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-getfacl [-R] &lt;path&gt;]</span><br><span class="line">	[-getfattr [-R] &#123;-n name | -d&#125; [-e en] &lt;path&gt;]</span><br><span class="line">	[-getmerge [-nl] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-head &lt;file&gt;]</span><br><span class="line">	[-<span class="built_in">help</span> [cmd ...]]</span><br><span class="line">	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [&lt;path&gt; ...]]</span><br><span class="line">	[-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line">	[-moveFromLocal [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-put [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] [-q &lt;thread pool queue size&gt;] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span><br><span class="line">	[-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]</span><br><span class="line"></span><br></pre></td></tr></table></figure>









<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建输入文件夹</span></span><br><span class="line">hadoop fs mkdir input</span><br><span class="line"><span class="comment"># 创建文件</span></span><br><span class="line">touch wordcount.txt</span><br><span class="line"><span class="comment"># 输入单词</span></span><br><span class="line"><span class="comment"># 上传文件到HDFS</span></span><br><span class="line">hadoop fs -put wordcount.txt /delaiwen/wensente</span><br><span class="line"><span class="comment"># 获取文件从HDFS</span></span><br><span class="line">hadoop fs -get /delaiwen/wensente/wordcount.txt</span><br><span class="line"><span class="comment"># 开始计算</span></span><br><span class="line">hadoop jar hadoop-mapreduce-examples-3.2.3.jar wordcount /delaiwen/wensente /output</span><br><span class="line"><span class="comment"># 默认是hdfs,如果是file:///output可以将输出保存到本地</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="MapReduce程序计算单词总数"><a href="#MapReduce程序计算单词总数" class="headerlink" title="MapReduce程序计算单词总数"></a>MapReduce程序计算单词总数</h3><ol>
<li><p>主类继承Configured同时实现Tool接口用作入口方法。需要设置配置文件生成job,设置map类以及reduce类,设置输入输出格式，接收参数用以输出数据</p>
</li>
<li><p>Map实现类实现Mapper泛型类(keyin,valuein,keyout,valueout)，TextInputFormat会让读取到的每一行都调用Map类的map方法，map方法的入参为&lt;keyin,valuein&gt;，最后返回一个键值对给reduce，也就是将&lt;keyout,valueout&gt;写到context上</p>
</li>
<li><p>Reduce实现类实现Reducer泛型类同上，这个类的reduce方法会入参为&lt;keyin,可迭代对象集合&gt;，每一个key相同的&lt;key,value&gt;集合会调用这个方法</p>
</li>
</ol>
<p>比如上面写了&lt;a,1&gt;,&lt;a,1&gt;,&lt;b,1&gt;,&lt;b,1&gt;,&lt;b,1&gt;,&lt;b,1&gt;那么这个方法会调用2次入参分别为&lt;a,{1,1}&gt;以及&lt;b,{1,1,1}&gt;,如果要统计总数那么将1相加就是结果了</p>
<ol start="4">
<li><p>将编写好的文件上传到HDFS文件系统,<code>hadoop fs -put /usr/local/hadoop/words /user/root/</code>  </p>
</li>
<li><p>编译完成后将jar包上传到服务器,通过命令<code>hadoop jar xxxx.jar /input/words /output </code> 运行jar</p>
</li>
<li><p>查看结果<code>hadoop fs -cat /output/part-r-00000 | tail -f | awk &#39;&#123;print $2&#125;&#39;</code></p>
</li>
</ol>
<h3 id="MapReduce程序运行原理"><a href="#MapReduce程序运行原理" class="headerlink" title="MapReduce程序运行原理"></a>MapReduce程序运行原理</h3><ul>
<li><strong>Map</strong></li>
</ul>
<p>将每一行读取到的数据返回成key,value，键和值的类型也是任意的，其中键不同于一般的标志属性，即键没有唯一性。</p>
<p>大致流程:①分片合并,默认分片大小为128MB②将每一行解析成键值对,默认键是每一行的起止位置字节,值是该行内容③将解析出的每一行都调用map方法,几个键值对调用几次map方法,而每一次map方法会输出n个键值对,n&gt;=0</p>
<ul>
<li><strong>Shuffle</strong></li>
</ul>
<p><strong>shuffle阶段是指从Map结束到Reduce开始之间的过程</strong>。从下这张图中可以了解shuffle所处的位置。包括分区,排序,合并</p>
<p><img src="https://testmybuck.oss-cn-beijing.aliyuncs.com/img/image-20220930183346132.png" alt="image-20220930183346132"></p>
<p>①根据键对不同键值对进行分区(partion)②对分好区的数据进行排序(sort),如果达到设置阈值的80%那么会溢出写,真正开始将数据写到磁盘,前面的数据保存在内存缓冲区.当map任务完成时，会把内存缓冲区中最后的结果也写到一个溢出写文件中③将前面多个溢写的文件用过归并法合并成当前reducer的最终数据(merge)，当所用reducer完成后还会再次通过reducer合并结果。</p>
<p><img src="https://testmybuck.oss-cn-beijing.aliyuncs.com/img/image-20220930184805278.png" alt="image-20220930184805278"></p>
<ul>
<li><strong>Reduce</strong></li>
</ul>
<p>将分好组的key，value重新输出为新的key,value.</p>
<p>​     copy阶段reduce任务启动一些copy线程（默认值是5个线程，可设置mapred.reduce.parallel.copies属性），通过HTTP方式把TaskTracker目录下的map输出结果复制到内存缓冲区（这里缓冲区大小比map端灵活，是基于JVM的heap size设置的。因为在copy阶段不执行reduce操作，所以绝大部分内存都给copy线程使用）。当缓冲区中的数据达到阈值，就进行溢出写操作（与map端类似）。</p>
<p>​    sort阶段其实，这里的所说的sort更恰当的说是merge，因为排序是在map端进行的，而这个阶段的任务是合并来自多个map端的输出结果。比如，有50个map输出，而合并因子是10（由io.sort.factor属性设置），那么将进行5趟合并，每趟合并10个文件。最后合并成5个文件。</p>
<p>​    reduce阶段 对sort阶段生成的文件执行reduce操作，把输出结果放到HDFS。</p>
<p>map与reduce中都有setup,cleanup提供给开发者注入</p>
<h3 id="自定义类"><a href="#自定义类" class="headerlink" title="自定义类"></a>自定义类</h3><p>因此可以通过自定义一些类实现自己的功能:</p>
<ul>
<li>自定义Combiner</li>
</ul>
<p>Combiner可以减少Map阶段的中间输出结果数，降低网络开销。默认情况下是没有Combiner的。用户自定义的Combiner要求是Reducer的子类，以Map的输出&lt;key,value&gt;作为Combiner的输入&lt;key,value&gt;和输出&lt;key,value&gt;，也就是说Combiner的输入和输出必须是一样的。因为combiner只负责合并结果</p>
<p> 可以通过job.setCombinerClass设置combiner的处理类，MapReduce框架不保证一定会调用该类的方法。如果reduce的输入和输出一样，则可以直接用reduce类作为combiner</p>
<ul>
<li>自定义Partioner</li>
</ul>
<p> Partitioner是用于确定map输出的&lt;key,value&gt;对应的处理reducer是那个节点。默认MapReduce任务reduce个数为1个，此时Partitioner其实没有什么效果，但是当我们将reduce个数修改为多个的时候，partitioner就会决定key所对应reduce的节点序号(从0开始)。</p>
<p> 可以通过job.setPartitionerClass方法指定Partitioner类，默认情况下使用HashPartitioner（默认调用key的hashCode方法）。</p>
<ul>
<li>自定义Group</li>
</ul>
<p> GroupingComparator是用于将Map输出的&lt;key,value&gt;进行分组组合成&lt;key,List<value>&gt;的关键类，直白来讲就是用于确定key1和key2是否属于同一组，如果是同一组，就将map的输出value进行组合。</p>
<p> 要求我们自定义的类实现自接口RawComparator，可以通过job.setGroupingComparatorClass方法指定比较类。默认情况下使用WritableComparator，但是最终调用key的compareTo方法进行比较。</p>
<ul>
<li>自定义Sort</li>
</ul>
<p> SortComparator是用于将Map输出的&lt;key,value&gt;进行key排序的关键类， 直白来讲就是用于确定key1所属组和key2所属组那个在前，那个在后。</p>
<p> 要求我们自定义的类实现自接口RawComparator，可以通过job.setSortComparatorClass方法指定比较类。默认情况下使用WritableComparator，但是最终调用key的compareTo方法进行比较。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/hexo/" rel="tag"># hexo</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/p/65046/" rel="prev" title="JAVA集合类">
                  <i class="fa fa-chevron-left"></i> JAVA集合类
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>





<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AGA</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  





</body>
</html>
